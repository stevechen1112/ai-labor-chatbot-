"""
è‡ªå‹•ç”ŸæˆçŸ¥è­˜åœ–è­œ

å¾ä»¥ä¸‹æ•¸æ“šæºå»ºç«‹ï¼š
1. citation_validation.json - æ¢æ–‡å…§å®¹èˆ‡é—œè¯
2. law_guides.yaml - ä¸»é¡Œèˆ‡æ ¸å¿ƒæ¢æ–‡
3. æ³•å¾‹å°ˆå®¶å®šç¾©çš„é å®šç¾©æƒ…å¢ƒ
"""
import sys
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.path.insert(0, '.')

import json
import yaml
from pathlib import Path
from typing import Dict, List, Set

ROOT = Path(__file__).resolve().parents[1]

def load_citation_validation():
    """è¼‰å…¥å¼•ç”¨é©—è­‰è³‡æ–™åº«"""
    path = ROOT / "data" / "citation_validation.json"
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)

def load_law_guides():
    """è¼‰å…¥ä¸»é¡Œæ˜ å°„"""
    path = ROOT / "data" / "law_guides.yaml"
    with open(path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def normalize_article_id(law_name: str, article_no: str) -> str:
    """æ¨™æº–åŒ–æ¢æ–‡ID"""
    return f"{law_name}ç¬¬{article_no}æ¢"

def extract_entities(validation_db: Dict, law_guides: Dict) -> Dict:
    """æå–å¯¦é«”ï¼ˆæ¢æ–‡ï¼‰"""
    entities = {}
    
    # å¾ validation_db æå–
    validated_articles = validation_db.get("validated_articles", {})
    for law_name, law_data in validated_articles.items():
        articles = law_data.get("articles", {})
        for article_no, article_data in articles.items():
            entity_id = normalize_article_id(law_name, article_no)
            
            # æå–é—œéµè©
            keywords = article_data.get("key_phrases", [])[:5]  # æœ€å¤š5å€‹
            
            # å¾ä¸»é¡Œæ˜ å°„ä¸­æ‰¾é©ç”¨ä¸»é¡Œ
            applies_to = []
            for topic_id, topic in law_guides.get("topics", {}).items():
                core_articles = topic.get("core_articles", [])
                for ca in core_articles:
                    if ca.get("law") == law_name and str(article_no) in [str(a) for a in ca.get("articles", [])]:
                        applies_to.append(topic.get("name"))
            
            entities[entity_id] = {
                "type": "æ¢æ–‡",
                "law": law_name,
                "article": article_no,
                "title": article_data.get("heading", ""),
                "topics": applies_to,
                "keywords": keywords,
                "applies_to": applies_to
            }
    
    print(f"âœ… æå– {len(entities)} å€‹æ¢æ–‡å¯¦é«”")
    return entities

def extract_relations(validation_db: Dict, entities: Dict) -> List[Dict]:
    """æå–é—œè¯"""
    relations = []
    relation_set = set()  # é¿å…é‡è¤‡
    
    validated_articles = validation_db.get("validated_articles", {})
    
    # 1. å¾ related_articles æå–åƒç…§é—œä¿‚
    for law_name, law_data in validated_articles.items():
        articles = law_data.get("articles", {})
        for article_no, article_data in articles.items():
            from_id = normalize_article_id(law_name, article_no)
            
            related = article_data.get("related_articles", [])
            for rel_article in related:
                to_id = normalize_article_id(law_name, rel_article)
                
                if to_id in entities and from_id != to_id:
                    rel_key = (from_id, to_id, "åƒç…§")
                    if rel_key not in relation_set:
                        relation_set.add(rel_key)
                        relations.append({
                            "from": from_id,
                            "to": to_id,
                            "type": "åƒç…§",
                            "description": f"{from_id}åƒç…§{to_id}"
                        })
    
    # 2. åŒä¸€æ³•è¦çš„ç›¸é„°æ¢æ–‡é—œè¯ï¼ˆç« ç¯€é—œä¿‚ï¼‰
    for law_name, law_data in validated_articles.items():
        articles = law_data.get("articles", {})
        article_numbers = sorted(
            articles.keys(),
            key=lambda x: (int(x.split('-')[0]) if '-' in x else int(x)) if x.isdigit() or '-' in x else 999999
        )
        
        for i, article_no in enumerate(article_numbers):
            if i > 0:  # èˆ‡å‰ä¸€æ¢å»ºç«‹ã€Œé †åºé—œä¿‚ã€
                from_id = normalize_article_id(law_name, article_numbers[i-1])
                to_id = normalize_article_id(law_name, article_no)
                rel_key = (from_id, to_id, "é †åºç›¸é„°")
                if rel_key not in relation_set and from_id in entities and to_id in entities:
                    relation_set.add(rel_key)
                    relations.append({
                        "from": from_id,
                        "to": to_id,
                        "type": "é †åºç›¸é„°",
                        "description": f"{from_id}èˆ‡{to_id}ç‚ºç›¸é„°æ¢æ–‡"
                    })
    
    # æ·»åŠ é‚è¼¯é—œè¯ï¼ˆåŸºæ–¼å°ˆå®¶çŸ¥è­˜ï¼‰
    expert_relations = [
        {
            "from": "å‹å‹•åŸºæº–æ³•ç¬¬22æ¢",
            "to": "å‹å‹•åŸºæº–æ³•ç¬¬26æ¢",
            "type": "è£œå……èªªæ˜",
            "description": "ç¬¬22æ¢è¦å®šå…¨é¡çµ¦ä»˜åŸå‰‡ï¼Œç¬¬26æ¢ç¦æ­¢é æ‰£ï¼Œå½¢æˆé›™é‡ä¿éšœ"
        },
        {
            "from": "å‹å‹•åŸºæº–æ³•ç¬¬12æ¢",
            "to": "å‹å‹•åŸºæº–æ³•ç¬¬22æ¢",
            "type": "ç›¸é—œä½†ä¸äº’æ–¥",
            "description": "æ› è·åš´é‡å¯ä¾ç¬¬12æ¢è§£åƒ±ï¼Œä½†è§£åƒ±å‰çš„å·¥è³‡ä»æ‡‰ä¾ç¬¬22æ¢å…¨é¡çµ¦ä»˜"
        },
        {
            "from": "å‹å‹•åŸºæº–æ³•ç¬¬24æ¢",
            "to": "å‹å‹•åŸºæº–æ³•ç¬¬32æ¢",
            "type": "é…å¥—é©ç”¨",
            "description": "ç¬¬24æ¢è¦å®šåŠ ç­è²»ï¼Œç¬¬32æ¢è¦å®šå»¶é•·å·¥æ™‚ä¸Šé™ï¼Œå…©è€…é…å¥—é©ç”¨"
        },
        {
            "from": "å‹å‹•åŸºæº–æ³•ç¬¬38æ¢",
            "to": "å‹å‹•åŸºæº–æ³•æ–½è¡Œç´°å‰‡ç¬¬24æ¢",
            "type": "ç´°å‰‡è£œå……",
            "description": "æ–½è¡Œç´°å‰‡ç¬¬24æ¢è£œå……ç¬¬38æ¢ç‰¹ä¼‘çš„å…·é«”è¨ˆç®—æ–¹å¼"
        },
        {
            "from": "æ€§åˆ¥å·¥ä½œå¹³ç­‰æ³•ç¬¬15æ¢",
            "to": "æ€§åˆ¥å·¥ä½œå¹³ç­‰æ³•ç¬¬16æ¢",
            "type": "é€£çºŒé©ç”¨",
            "description": "ç”¢å‡ï¼ˆç¬¬15æ¢ï¼‰èˆ‡è‚²å¬°ç•™è·åœè–ªï¼ˆç¬¬16æ¢ï¼‰å¯é€£çºŒä½¿ç”¨"
        },
        {
            "from": "å‹å‹•åŸºæº–æ³•ç¬¬59æ¢",
            "to": "å‹å·¥è·æ¥­ç½å®³ä¿éšªåŠä¿è­·æ³•ç¬¬18æ¢",
            "type": "å„ªå…ˆé©ç”¨",
            "description": "è·ç½è£œå„Ÿå„ªå…ˆé©ç”¨å‹è·ä¿æ³•ï¼Œé›‡ä¸»è²¬ä»»è£œå……é©ç”¨å‹åŸºæ³•ç¬¬59æ¢"
        }
    ]
    
    for rel in expert_relations:
        if rel["from"] in entities and rel["to"] in entities:
            relations.append(rel)
    
    print(f"âœ… æå– {len(relations)} å€‹é—œè¯")
    return relations

def create_scenarios(law_guides: Dict) -> Dict:
    """å»ºç«‹é å®šç¾©æƒ…å¢ƒ"""
    scenarios = {}
    
    # åŸºæ–¼ä¸»é¡Œæ˜ å°„å»ºç«‹æƒ…å¢ƒ
    scenario_mapping = {
        "wage_deduction": {
            "name": "æ› è·æ‰£è–ª",
            "description": "å‹å·¥æ› è·æ™‚ï¼Œé›‡ä¸»å¦‚ä½•åˆæ³•æ‰£é™¤å·¥è³‡",
            "required_articles": [
                "å‹å‹•åŸºæº–æ³•ç¬¬22æ¢",
                "å‹å‹•åŸºæº–æ³•ç¬¬26æ¢",
                "å‹å‹•åŸºæº–æ³•ç¬¬12æ¢"
            ],
            "reasoning": "æ› è·æ—¥å¯æ‰£è–ªï¼ˆæœªæä¾›å‹å‹™ï¼‰ï¼Œä½†ä¸å¾—æ“´å¤§æ‰£é™¤å…¶ä»–å‡ºå‹¤æ—¥å·¥è³‡ï¼ˆç¬¬22/26æ¢ï¼‰ã€‚åš´é‡æ› è·å¯ä¾ç¬¬12æ¢è§£åƒ±ã€‚",
            "common_errors": [
                "èª¤ä»¥ç‚ºå¯æ‰£é™¤å…¨å‹¤çé‡‘ï¼ˆéœ€çœ‹çé‡‘æ€§è³ªï¼‰",
                "æ“´å¤§æ‰£é™¤å…¶ä»–æ—¥å·¥è³‡ï¼ˆé•åç¬¬26æ¢ï¼‰",
                "æœªä¾æ³•å®šç¨‹åºç›´æ¥æ‰£æ¬¾"
            ]
        },
        "overtime": {
            "name": "åŠ ç­è²»è¨ˆç®—",
            "description": "å»¶é•·å·¥ä½œæ™‚é–“çš„å·¥è³‡å¦‚ä½•è¨ˆç®—",
            "required_articles": [
                "å‹å‹•åŸºæº–æ³•ç¬¬24æ¢",
                "å‹å‹•åŸºæº–æ³•ç¬¬32æ¢",
                "å‹å‹•åŸºæº–æ³•ç¬¬32-1æ¢"
            ],
            "reasoning": "ç¬¬24æ¢æ˜å®šåŠ ç­è²»ç‡ï¼ˆå¹³æ—¥1.34å€ã€ä¼‘æ¯æ—¥å‰2å°æ™‚1.34å€å¾Œ1.67å€ï¼‰ï¼Œç¬¬32æ¢è¦ç¯„å»¶é•·å·¥æ™‚ä¸Šé™ã€‚",
            "common_errors": [
                "ä¼‘æ¯æ—¥åŠ ç­è²»è¨ˆç®—éŒ¯èª¤",
                "æœªä¾æ³•çµ¦äºˆè£œä¼‘æˆ–åŠ ç­è²»é¸æ“‡æ¬Š",
                "è¶…éæ³•å®šå»¶é•·å·¥æ™‚ä¸Šé™"
            ]
        },
        "annual_leave": {
            "name": "ç‰¹ä¼‘å¤©æ•¸",
            "description": "å‹å·¥ä¾å¹´è³‡äº«æœ‰çš„ç‰¹åˆ¥ä¼‘å‡å¤©æ•¸",
            "required_articles": [
                "å‹å‹•åŸºæº–æ³•ç¬¬38æ¢",
                "å‹å‹•åŸºæº–æ³•æ–½è¡Œç´°å‰‡ç¬¬24æ¢",
                "å‹å‹•åŸºæº–æ³•æ–½è¡Œç´°å‰‡ç¬¬24-1æ¢"
            ],
            "reasoning": "ç¬¬38æ¢æ˜å®šå„å¹´è³‡ç‰¹ä¼‘å¤©æ•¸ï¼Œæ–½è¡Œç´°å‰‡ç¬¬24/24-1æ¢è¦ç¯„ç‰¹ä¼‘æ’å®šèˆ‡æœªä¼‘å·¥è³‡è¨ˆç®—ã€‚",
            "common_errors": [
                "å¹´è³‡è¨ˆç®—éŒ¯èª¤",
                "æœªä¼‘ç‰¹ä¼‘æœªä¾æ³•çµ¦ä»˜å·¥è³‡",
                "é™åˆ¶å‹å·¥ç‰¹ä¼‘ä½¿ç”¨"
            ]
        },
        "tardiness": {
            "name": "é²åˆ°æ‰£æ¬¾",
            "description": "å‹å·¥é²åˆ°æ™‚çš„å·¥è³‡æ‰£é™¤è¦ç¯„",
            "required_articles": [
                "å‹å‹•åŸºæº–æ³•ç¬¬22æ¢",
                "å‹å‹•åŸºæº–æ³•ç¬¬26æ¢"
            ],
            "reasoning": "é²åˆ°å¯æ‰£é™¤è©²æ™‚æ®µå·¥è³‡ï¼ˆä¸æä¾›å‹å‹™ä¸çµ¦è–ªï¼‰ï¼Œä½†ä¸å¾—æ“´å¤§æ‰£é™¤æˆ–ä½œç‚ºæ‡²ç½°æ€§æ‰£æ¬¾ï¼ˆç¬¬26æ¢ï¼‰ã€‚",
            "common_errors": [
                "æ‡²ç½°æ€§æ‰£æ¬¾ï¼ˆå¦‚é²åˆ°1åˆ†é˜æ‰£1å°æ™‚ï¼‰",
                "æ‰£é™¤å…¨å‹¤çé‡‘æœªç¬¦åˆæ³•å®šè¦ç¯„"
            ]
        },
        "maternity_leave": {
            "name": "ç”¢å‡è¦å®š",
            "description": "å¥³å·¥åˆ†å¨©å‰å¾Œçš„å‡æœŸèˆ‡å·¥è³‡",
            "required_articles": [
                "æ€§åˆ¥å·¥ä½œå¹³ç­‰æ³•ç¬¬15æ¢",
                "å‹å‹•åŸºæº–æ³•ç¬¬50æ¢"
            ],
            "reasoning": "æ€§å¹³æ³•ç¬¬15æ¢è¦ç¯„ç”¢å‡8é€±ï¼ˆå¯å½ˆæ€§åˆ†é…ï¼‰ï¼Œå·¥è³‡ç…§çµ¦ã€‚å‹åŸºæ³•ç¬¬50æ¢ç‚ºåŸºç¤è¦ç¯„ã€‚",
            "common_errors": [
                "ç”¢å‡æœŸé–“æœªçµ¦ä»˜å·¥è³‡",
                "å¼·åˆ¶è¦æ±‚ä¸€æ¬¡è«‹å®Œ8é€±",
                "ç”¢æª¢å‡æœªä¾æ³•çµ¦äºˆ"
            ]
        },
        "parental_leave": {
            "name": "è‚²å¬°ç•™è·åœè–ª",
            "description": "è‚²å¬°ç•™è·åœè–ªçš„ç”³è«‹è³‡æ ¼èˆ‡æ´¥è²¼",
            "required_articles": [
                "æ€§åˆ¥å·¥ä½œå¹³ç­‰æ³•ç¬¬16æ¢",
                "æ€§åˆ¥å·¥ä½œå¹³ç­‰æ³•ç¬¬17æ¢",
                "å°±æ¥­ä¿éšªæ³•ç¬¬19-1æ¢"
            ],
            "reasoning": "æ€§å¹³æ³•ç¬¬16/17æ¢è¦ç¯„è‚²å¬°å‡ç”³è«‹ï¼Œå°±ä¿æ³•ç¬¬19-1æ¢è¦ç¯„è‚²å¬°æ´¥è²¼ï¼ˆæŠ•ä¿è–ªè³‡60%ï¼‰ã€‚",
            "common_errors": [
                "æ‹’çµ•å‹å·¥è‚²å¬°ç•™åœç”³è«‹",
                "è‚²å¬°æœŸé–“è¦æ±‚é›¢è·",
                "å¾©è·å¾Œæœªçµ¦äºˆåŸè·æˆ–ç›¸ç•¶è·ä½"
            ]
        },
        "severance_pay": {
            "name": "è³‡é£è²»è¨ˆç®—",
            "description": "è³‡é£è²»çš„è¨ˆç®—æ–¹å¼èˆ‡çµ¦ä»˜",
            "required_articles": [
                "å‹å‹•åŸºæº–æ³•ç¬¬11æ¢",
                "å‹å‹•åŸºæº–æ³•ç¬¬17æ¢",
                "å‹å·¥é€€ä¼‘é‡‘æ¢ä¾‹ç¬¬12æ¢"
            ],
            "reasoning": "ç¬¬11æ¢æ˜å®šè³‡é£äº‹ç”±ï¼Œç¬¬17æ¢èˆ‡é€€æ¢ç¬¬12æ¢åˆ†åˆ¥è¦ç¯„èˆŠåˆ¶èˆ‡æ–°åˆ¶è³‡é£è²»è¨ˆç®—ã€‚",
            "common_errors": [
                "è³‡é£äº‹ç”±ä¸ç¬¦æ³•å®š",
                "è³‡é£è²»è¨ˆç®—éŒ¯èª¤",
                "æœªä¾æ³•é å‘Šæˆ–çµ¦ä»˜é å‘ŠæœŸå·¥è³‡"
            ]
        },
        "occupational_injury": {
            "name": "è·æ¥­ç½å®³è£œå„Ÿ",
            "description": "è·ç½å‹å·¥çš„é†«ç™‚èˆ‡è£œå„Ÿ",
            "required_articles": [
                "å‹å·¥è·æ¥­ç½å®³ä¿éšªåŠä¿è­·æ³•ç¬¬18æ¢",
                "å‹å·¥è·æ¥­ç½å®³ä¿éšªåŠä¿è­·æ³•ç¬¬63æ¢",
                "å‹å‹•åŸºæº–æ³•ç¬¬59æ¢"
            ],
            "reasoning": "å‹è·ä¿æ³•ç¬¬18/63æ¢è¦ç¯„è·ç½ä¿éšªçµ¦ä»˜ï¼Œå‹åŸºæ³•ç¬¬59æ¢è¦ç¯„é›‡ä¸»è£œå„Ÿè²¬ä»»ã€‚",
            "common_errors": [
                "è·ç½æœŸé–“æœªçµ¦ä»˜åŸé ˜å·¥è³‡",
                "è·ç½å‹å·¥ç„¡æ³•å‹ä»»åŸå·¥ä½œæœªå®‰ç½®é©ç•¶å·¥ä½œ",
                "æœªä¾æ³•çµ¦ä»˜è£œå„Ÿ"
            ]
        },
        "salary_delay": {
            "name": "å»¶é²ç™¼è–ª",
            "description": "å·¥è³‡å»¶é²çµ¦ä»˜çš„æ³•å¾‹è²¬ä»»",
            "required_articles": [
                "å‹å‹•åŸºæº–æ³•ç¬¬21æ¢",
                "å‹å‹•åŸºæº–æ³•ç¬¬79æ¢"
            ],
            "reasoning": "ç¬¬21æ¢è¦ç¯„å·¥è³‡å®šæœŸçµ¦ä»˜ï¼Œç¬¬79æ¢æ˜å®šé•æ³•ç½°å‰‡ï¼ˆ2-100è¬å…ƒç½°é°ï¼‰ã€‚",
            "common_errors": [
                "ä»¥å„ç¨®ç†ç”±æ‹–å»¶ç™¼è–ª",
                "æœªä¾ç´„å®šæ—¥æœŸçµ¦ä»˜",
                "å¼·åˆ¶å»¶å¾Œç™¼è–ªæ—¥"
            ]
        },
        "probation_period": {
            "name": "è©¦ç”¨æœŸè¦ç¯„",
            "description": "è©¦ç”¨æœŸé–“çš„å‹å‹•æ¬Šç›Š",
            "required_articles": [
                "å‹å‹•åŸºæº–æ³•ç¬¬11æ¢",
                "å‹å‹•åŸºæº–æ³•ç¬¬15æ¢"
            ],
            "reasoning": "è©¦ç”¨æœŸé–“ä»å—å‹åŸºæ³•ä¿éšœï¼Œçµ‚æ­¢å¥‘ç´„éœ€é©ç”¨ç¬¬11/15æ¢ï¼Œä¸å¾—ä»»æ„è§£åƒ±ã€‚",
            "common_errors": [
                "è©¦ç”¨æœŸè–ªè³‡ä½æ–¼åŸºæœ¬å·¥è³‡",
                "è©¦ç”¨æœŸé–“ä»»æ„è§£åƒ±",
                "è©¦ç”¨æœŸæœªæä¾›å‹å¥ä¿"
            ]
        }
    }
    
    for topic_id, scenario_template in scenario_mapping.items():
        if topic_id in law_guides.get("topics", {}):
            scenarios[topic_id] = scenario_template
    
    print(f"âœ… å»ºç«‹ {len(scenarios)} å€‹é å®šç¾©æƒ…å¢ƒ")
    return scenarios

def generate_knowledge_graph():
    """ä¸»å‡½æ•¸ï¼šç”ŸæˆçŸ¥è­˜åœ–è­œ"""
    print("ğŸš€ é–‹å§‹ç”ŸæˆçŸ¥è­˜åœ–è­œ...")
    print("=" * 60)
    
    # è¼‰å…¥æ•¸æ“š
    print("\n[æ­¥é©Ÿ 1] è¼‰å…¥æ•¸æ“šæº...")
    validation_db = load_citation_validation()
    law_guides = load_law_guides()
    print(f"  - è¼‰å…¥ {len(validation_db)} éƒ¨æ³•è¦")
    print(f"  - è¼‰å…¥ {len(law_guides.get('topics', {}))} å€‹ä¸»é¡Œ")
    
    # æå–å¯¦é«”
    print("\n[æ­¥é©Ÿ 2] æå–æ¢æ–‡å¯¦é«”...")
    entities = extract_entities(validation_db, law_guides)
    
    # æå–é—œè¯
    print("\n[æ­¥é©Ÿ 3] æå–æ¢æ–‡é—œè¯...")
    relations = extract_relations(validation_db, entities)
    
    # å»ºç«‹æƒ…å¢ƒ
    print("\n[æ­¥é©Ÿ 4] å»ºç«‹é å®šç¾©æƒ…å¢ƒ...")
    scenarios = create_scenarios(law_guides)
    
    # çµ„è£çŸ¥è­˜åœ–è­œ
    kg = {
        "metadata": {
            "version": "1.0.0",
            "created_at": "2025-11-14",
            "description": "å°ç£å‹å‹•æ³•è¦çŸ¥è­˜åœ–è­œ",
            "entity_count": len(entities),
            "relation_count": len(relations),
            "scenario_count": len(scenarios)
        },
        "entities": entities,
        "relations": relations,
        "scenarios": scenarios
    }
    
    # å„²å­˜
    output_path = ROOT / "data" / "knowledge_graph.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(kg, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 60)
    print(f"âœ… çŸ¥è­˜åœ–è­œç”Ÿæˆå®Œæˆï¼")
    print(f"   è·¯å¾‘ï¼š{output_path}")
    print(f"   å¯¦é«”æ•¸ï¼š{len(entities)}")
    print(f"   é—œè¯æ•¸ï¼š{len(relations)}")
    print(f"   æƒ…å¢ƒæ•¸ï¼š{len(scenarios)}")
    print("=" * 60)

if __name__ == "__main__":
    generate_knowledge_graph()

