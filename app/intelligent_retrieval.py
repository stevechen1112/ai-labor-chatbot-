"""
æ™ºèƒ½æª¢ç´¢æ¨¡çµ„ - Phase 2.5 æ ¸å¿ƒåŠŸèƒ½

åŠŸèƒ½ï¼š
1. å‰ç½®åˆ†æï¼ˆPreRetrievalAnalyzerï¼‰- è®“ LLM åˆ†æå•é¡Œæ¶‰åŠå“ªäº›æ³•å¾‹é¢å‘
2. è¿­ä»£å¼æª¢ç´¢ï¼ˆIterativeRetrieverï¼‰- LLM åè¦†æª¢æŸ¥ä¸¦è£œè¶³ç¼ºå¤±çš„æ³•æ¢
3. æœ€çµ‚é©—è­‰ï¼ˆPostRetrievalValidatorï¼‰- ç”Ÿæˆç­”æ¡ˆå‰æœ€å¾Œç¢ºèª

ä½œè€…ï¼šAI Assistant
ç‰ˆæœ¬ï¼š2.5.0
æ—¥æœŸï¼š2025-11-14
"""

from __future__ import annotations

import sys
import io
# ä¿®å¾© Windows ç·¨ç¢¼å•é¡Œ
if sys.platform == 'win32' and sys.stdout.encoding != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

import json
import time
from typing import List, Dict, Optional
import re
from pydantic import BaseModel

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    OpenAI = None


# ============================================================
# Pydantic Models
# ============================================================

class LegalAspect(BaseModel):
    """æ³•å¾‹é¢å‘"""
    type: str  # "ç¨‹åº" | "å¯¦é«”æ¬Šåˆ©" | "è¡Œæ”¿ç¾©å‹™" | "ç½°å‰‡"
    description: str
    suggested_laws: List[str]


class PreAnalysisResult(BaseModel):
    """å‰ç½®åˆ†æçµæœ"""
    aspects: List[LegalAspect]
    suggested_laws: List[str]
    estimated_complexity: str  # "simple" | "medium" | "complex"
    reasoning: str


class RetrievalCheckResult(BaseModel):
    """æª¢ç´¢å®Œæ•´æ€§æª¢æŸ¥çµæœ"""
    is_sufficient: bool
    reason: str
    missing_articles: List[Dict[str, str]]  # [{"law": "...", "article": "...", "reason": "..."}]
    confidence: float


class FinalValidationResult(BaseModel):
    """æœ€çµ‚é©—è­‰çµæœ"""
    status: str  # "PASS" | "INSUFFICIENT" | "WARNING"
    concerns: List[str]
    missing_aspects: List[str]


# ============================================================
# Main Intelligent Retriever Class
# ============================================================

class IntelligentRetriever:
    """
    æ™ºèƒ½æª¢ç´¢å™¨ï¼ˆPhase 2.5 æ ¸å¿ƒï¼‰
    
    ä½¿ç”¨ LLM åƒèˆ‡æª¢ç´¢éç¨‹ï¼Œè‡ªå‹•ç™¼ç¾ä¸¦è£œè¶³ç¼ºå¤±çš„æ³•æ¢ã€‚
    
    ä¸‰å±¤æ©Ÿåˆ¶ï¼š
    1. å‰ç½®åˆ†æï¼šç†è§£å•é¡Œæ¶‰åŠçš„æ³•å¾‹é¢å‘
    2. è¿­ä»£å¼æª¢ç´¢ï¼šåè¦†æª¢æŸ¥ä¸¦è£œå……ç¼ºå¤±çš„æ³•æ¢
    3. æœ€çµ‚é©—è­‰ï¼šç”Ÿæˆç­”æ¡ˆå‰çš„å“è³ªæŠŠé—œ
    """
    
    def __init__(self, api_key: str, model: str = "gpt-4o-mini"):
        """
        åˆå§‹åŒ–æ™ºèƒ½æª¢ç´¢å™¨
        
        Args:
            api_key: OpenAI API é‡‘é‘°
            model: LLM æ¨¡å‹åç¨±ï¼ˆé»˜èª gpt-4o-miniï¼‰
        """
        if not OPENAI_AVAILABLE:
            raise RuntimeError("OpenAI package not installed")
        
        if not api_key:
            raise RuntimeError("OpenAI API key not provided")
        
        self.client = OpenAI(api_key=api_key)
        self.model = model
        self.max_iterations = 2  # æœ€å¤šè¿­ä»£ 2 è¼ªï¼ˆé™ä½å»¶é²ï¼‰
        self.confidence_threshold = 0.8  # é«˜ä¿¡å¿ƒæ™‚æå‰é€€å‡º
        self.last_iterations = 0
        self.last_forced_additions = 0
        
        print(f"[IntelligentRetriever] Initialized with model: {self.model}")
    
    # ========== ç¬¬ä¸€å±¤ï¼šå‰ç½®åˆ†æ ==========
    
    def pre_analyze(self, query: str) -> PreAnalysisResult:
        """
        ç¬¬ä¸€å±¤ï¼šå‰ç½®æ™ºèƒ½åˆ†æ
        
        è®“ LLM åˆ†æå•é¡Œæ¶‰åŠçš„æ³•å¾‹é¢å‘ï¼ˆç¨‹åºã€å¯¦é«”æ¬Šåˆ©ã€è¡Œæ”¿ç¾©å‹™ã€ç½°å‰‡ç­‰ï¼‰ï¼Œ
        ä¸¦å»ºè­°æ‡‰è©²æª¢ç´¢å“ªäº›æ³•å¾‹ã€‚
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            
        Returns:
            PreAnalysisResult: åˆ†æçµæœ
        """
        print(f"[Phase 2.5] ç¬¬ä¸€å±¤ï¼šå‰ç½®åˆ†æ")
        
        # ğŸš€ å„ªåŒ–ï¼šç°¡åŒ– prompt æ¸›å°‘ token æ•¸
        prompt = f"""ä½ æ˜¯å°ç£å‹å‹•æ³•å¾‹å°ˆå®¶ã€‚åˆ†æå•é¡Œæ¶‰åŠçš„æ³•å¾‹é¢å‘ã€‚

å•é¡Œï¼š{query}

åˆ†æé¢å‘ï¼šç¨‹åºã€å¯¦é«”æ¬Šåˆ©ã€è¡Œæ”¿ç¾©å‹™ã€è²¬ä»»

JSON æ ¼å¼ï¼š
{{
    "aspects": [{{"type": "ç¨‹åº", "description": "ç°¡è¿°", "suggested_laws": ["æ³•å¾‹åç¨±"]}}],
    "suggested_laws": ["å‹å‹•åŸºæº–æ³•"],
    "estimated_complexity": "medium",
    "reasoning": "ç°¡è¦èªªæ˜"
}}
"""
        
        try:
            start_time = time.time()
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯å°ç£å‹å‹•æ³•å¾‹å°ˆå®¶ï¼Œæ“…é•·åˆ†ææ³•å¾‹å•é¡Œçš„å¤šç¶­åº¦ã€‚å›ç­”å¿…é ˆæ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            elapsed = time.time() - start_time
            
            result_json = json.loads(response.choices[0].message.content)
            result = PreAnalysisResult(**result_json)
            
            print(f"[Phase 2.5] âœ“ å‰ç½®åˆ†æå®Œæˆ ({elapsed:.2f}s)")
            print(f"[Phase 2.5]   è­˜åˆ¥ {len(result.aspects)} å€‹æ³•å¾‹é¢å‘")
            print(f"[Phase 2.5]   å»ºè­°æ³•å¾‹: {', '.join(result.suggested_laws)}")
            print(f"[Phase 2.5]   è¤‡é›œåº¦: {result.estimated_complexity}")
            
            return result
        
        except Exception as e:
            print(f"[Phase 2.5] âœ— å‰ç½®åˆ†æå¤±æ•—: {e}")
            # é™ç´šï¼šè¿”å›ç°¡å–®çš„åˆ†æçµæœ
            return PreAnalysisResult(
                aspects=[
                    LegalAspect(
                        type="å¯¦é«”æ¬Šåˆ©",
                        description="åŸºæœ¬å‹å‹•æ¬Šç›Š",
                        suggested_laws=["å‹å‹•åŸºæº–æ³•"]
                    )
                ],
                suggested_laws=["å‹å‹•åŸºæº–æ³•"],
                estimated_complexity="simple",
                reasoning="åˆ†æå¤±æ•—ï¼Œä½¿ç”¨é»˜èªè¨­å®š"
            )
    
    # ========== ç¬¬äºŒå±¤ï¼šè¿­ä»£å¼æª¢ç´¢ ==========
    
    def iterative_retrieve(
        self, 
        query: str, 
        pre_analysis: PreAnalysisResult,
        initial_results: List[Dict]
    ) -> List[Dict]:
        """
        ç¬¬äºŒå±¤ï¼šè¿­ä»£å¼æª¢ç´¢
        
        LLM åè¦†æª¢æŸ¥ç•¶å‰æª¢ç´¢çµæœæ˜¯å¦å®Œæ•´ï¼Œå¦‚æœä¸è¶³å‰‡è£œæª¢ç´¢ç¼ºå¤±çš„æ³•æ¢ã€‚
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            pre_analysis: å‰ç½®åˆ†æçµæœ
            initial_results: åˆå§‹æª¢ç´¢çµæœï¼ˆdict æ ¼å¼ï¼‰
            
        Returns:
            å¢å¼·å¾Œçš„æª¢ç´¢çµæœ
        """
        print(f"[Phase 2.5] ç¬¬äºŒå±¤ï¼šè¿­ä»£å¼æª¢ç´¢")
        
        results = initial_results.copy()
        iteration = 0
        forced_total = 0
        self.last_iterations = 0
        self.last_forced_additions = 0
        
        while iteration < self.max_iterations:
            iteration += 1
            self.last_iterations = iteration
            print(f"[Phase 2.5] ç¬¬ {iteration} è¼ªæª¢æŸ¥...")
            
            # è«‹ LLM æª¢æŸ¥ç•¶å‰æª¢ç´¢çµæœæ˜¯å¦è¶³å¤ 
            check_result = self._check_retrieval_completeness(
                query, 
                pre_analysis, 
                results
            )
            
            # å¦‚æœ LLM èªç‚ºè¶³å¤ ï¼ŒçµæŸè¿­ä»£
            if check_result.is_sufficient:
                print(f"[Phase 2.5] âœ“ LLM ç¢ºèªæª¢ç´¢å®Œæ•´ (confidence: {check_result.confidence:.2f})")
                break
            
            if check_result.confidence >= self.confidence_threshold and iteration > 1:
                print(f"[Phase 2.5] âš¡ Confidence é” {check_result.confidence:.2f}ï¼Œæå‰çµæŸ")
                break
            
            # LLM èªç‚ºä¸è¶³ï¼Œè£œæª¢ç´¢ç¼ºå°‘çš„æ³•æ¢
            print(f"[Phase 2.5] âš ï¸ LLM ç™¼ç¾ç¼ºå°‘ {len(check_result.missing_articles)} æ¢æ³•è¦")
            
            è£œå……æˆåŠŸ = 0
            for missing in check_result.missing_articles:
                # æª¢æŸ¥æ˜¯å¦å·²ç¶“å­˜åœ¨ï¼ˆé¿å…é‡è¤‡è£œå……ï¼‰
                normalized_article = self._normalize_article_no(missing.get("article", ""))
                already_exists = False
                for r in results:
                    existing_article = self._normalize_article_no(str(r.get("article_no", "")))
                    if (r.get("law_name") == missing["law"] or r.get("law_id") == missing["law"]) and \
                       existing_article == normalized_article:
                        already_exists = True
                        break
                
                if already_exists:
                    print(f"[Phase 2.5]   â– å·²å­˜åœ¨ï¼š{missing['law']} ç¬¬ {missing['article']} æ¢")
                    continue
                
                forced = self._force_retrieve(missing["law"], normalized_article)
                if forced:
                    # æ’å…¥åˆ°çµæœæœ€å‰é¢ï¼ˆé«˜å„ªå…ˆç´šï¼‰
                    results.insert(0, forced)
                    print(f"[Phase 2.5]   âœ“ è£œæª¢ç´¢ï¼š{missing['law']} ç¬¬ {missing['article']} æ¢")
                    è£œå……æˆåŠŸ += 1
                    forced_total += 1
                else:
                    print(f"[Phase 2.5]   âœ— ç„¡æ³•æª¢ç´¢ï¼š{missing['law']} ç¬¬ {missing['article']} æ¢")
            
            # å¦‚æœé€™è¼ªæ²’æœ‰æˆåŠŸè£œå……ä»»ä½•æ³•æ¢ï¼Œé¿å…ç„¡é™å¾ªç’°
            if è£œå……æˆåŠŸ == 0:
                print(f"[Phase 2.5] âš ï¸ ç„¡æ³•è£œå……æ›´å¤šæ³•æ¢ï¼ŒçµæŸè¿­ä»£")
                break
        
        if iteration >= self.max_iterations:
            print(f"[Phase 2.5] âš ï¸ é”åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•¸ ({self.max_iterations})ï¼Œå¯èƒ½ä»æœ‰éºæ¼")
        
        self.last_forced_additions = forced_total
        print(f"[Phase 2.5] âœ“ è¿­ä»£å¼æª¢ç´¢å®Œæˆï¼Œæœ€çµ‚çµæœ: {len(results)} æ¢")
        return results
    
    def _check_retrieval_completeness(
        self,
        query: str,
        pre_analysis: PreAnalysisResult,
        results: List[Dict]
    ) -> RetrievalCheckResult:
        """
        è®“ LLM æª¢æŸ¥æª¢ç´¢çµæœæ˜¯å¦å®Œæ•´
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            pre_analysis: å‰ç½®åˆ†æçµæœ
            results: ç•¶å‰æª¢ç´¢çµæœ
            
        Returns:
            RetrievalCheckResult: æª¢æŸ¥çµæœ
        """
        # æ ¼å¼åŒ–ç•¶å‰æª¢ç´¢çµæœ
        citations_summary = self._format_citations_for_check(results)
        aspects_summary = "\n".join([
            f"- {a.type}ï¼š{a.description}" for a in pre_analysis.aspects
        ])
        
        # ğŸš€ å„ªåŒ–ï¼šç°¡åŒ– prompt
        prompt = f"""å°ç£å‹å‹•æ³•å°ˆå®¶ã€‚åˆ¤æ–·æª¢ç´¢çµæœæ˜¯å¦å®Œæ•´ã€‚

å•é¡Œï¼š{query}

é¢å‘ï¼š{aspects_summary}

å·²æª¢ç´¢ï¼š
{citations_summary}

åˆ¤æ–·æ˜¯å¦å®Œæ•´ï¼Ÿç¼ºå°‘å“ªäº›æ³•æ¢ï¼Ÿ

JSONï¼š
{{
    "is_sufficient": false,
    "reason": "ç¼ºå°‘XX",
    "missing_articles": [{{"law": "æ³•å¾‹", "article": "XX", "reason": "åŸå› "}}],
    "confidence": 0.85
}}
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯æª¢ç´¢å“è³ªæª¢æŸ¥å°ˆå®¶ï¼Œå°ˆé–€åˆ¤æ–·æ³•æ¢æª¢ç´¢æ˜¯å¦å®Œæ•´ã€‚å›ç­”å¿…é ˆæ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                response_format={"type": "json_object"}
            )
            
            result_json = json.loads(response.choices[0].message.content)
            result = RetrievalCheckResult(**result_json)
            
            return result
        
        except Exception as e:
            print(f"[Phase 2.5] âœ— æª¢æŸ¥å¤±æ•—: {e}")
            # é™ç´šï¼šå‡è¨­æª¢ç´¢å·²ç¶“è¶³å¤ 
            return RetrievalCheckResult(
                is_sufficient=True,
                reason="æª¢æŸ¥å¤±æ•—ï¼Œå‡è¨­æª¢ç´¢è¶³å¤ ",
                missing_articles=[],
                confidence=0.5
            )
    
    def _format_citations_for_check(self, results: List[Dict]) -> str:
        """æ ¼å¼åŒ–æª¢ç´¢çµæœä¾› LLM æª¢æŸ¥"""
        lines = []
        for i, r in enumerate(results[:10], 1):  # åªåˆ—å‡ºå‰ 10 æ¢
            law = r.get("law_name") or r.get("law_id", "æœªçŸ¥æ³•å¾‹")
            art = r.get("article_no", "?")
            heading = r.get("heading", "")
            lines.append(f"{i}. {law} ç¬¬ {art} æ¢ï¼š{heading}")
        
        if len(results) > 10:
            lines.append(f"... ä»¥åŠå…¶ä»– {len(results) - 10} æ¢")
        
        return "\n".join(lines) if lines else "ï¼ˆå°šç„¡æª¢ç´¢çµæœï¼‰"
    
    def _force_retrieve(self, law_name: str, article_no: str) -> Optional[Dict]:
        """
        å¼·åˆ¶æª¢ç´¢æŒ‡å®šæ³•æ¢
        
        Args:
            law_name: æ³•å¾‹åç¨±
            article_no: æ¢è™Ÿ
            
        Returns:
            æª¢ç´¢åˆ°çš„æ³•æ¢ï¼ˆdict æ ¼å¼ï¼‰ï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å› None
        """
        try:
            from .articles import find_article
            
            result = find_article(law_name, article_no)
            if result:
                return {
                    "id": f"{law_name}_{article_no}",
                    "law_name": law_name,
                    "law_id": law_name,
                    "article_no": article_no,
                    "heading": result.get("heading", f"ç¬¬ {article_no} æ¢"),
                    "text": result.get("text", ""),
                    "source_file": result.get("law_file", ""),
                    "source": "intelligent_retrieval_forced"
                }
            return None
        except Exception as e:
            print(f"[Phase 2.5] âœ— å¼·åˆ¶æª¢ç´¢å¤±æ•— ({law_name} ç¬¬ {article_no} æ¢): {e}")
            return None

    def _normalize_article_no(self, article: str) -> str:
        """
        æ­£è¦åŒ–æ¢è™Ÿï¼šç§»é™¤ã€Œç¬¬ã€ã€Œæ¢ã€ç­‰å­—ï¼Œä¸¦å˜—è©¦è½‰æ›ä¸­æ–‡æ•¸å­—
        """
        if not article:
            return article
        # å…ˆå˜—è©¦æ“·å–æ•¸å­—
        digits = re.findall(r"[0-9]+", article)
        if digits:
            return digits[0]
        # å˜—è©¦ä¸­æ–‡æ•¸å­—
        chinese = re.sub(r"[ç¬¬æ¢\s]", "", article)
        value = self._chinese_to_int(chinese)
        if value is not None:
            return str(value)
        return article.strip()

    def _chinese_to_int(self, text: str) -> Optional[int]:
        if not text:
            return None
        mapping = {
            "é›¶": 0, "ã€‡": 0, "ä¸€": 1, "äºŒ": 2, "å…©": 2, "ä¸‰": 3, "å››": 4,
            "äº”": 5, "å…­": 6, "ä¸ƒ": 7, "å…«": 8, "ä¹": 9
        }
        text = text.replace("å…©", "äºŒ")
        if "å" in text:
            parts = text.split("å")
            tens_part = parts[0]
            ones_part = parts[1] if len(parts) > 1 else ""
            tens = mapping.get(tens_part[-1], 1) if tens_part else 1
            ones = mapping.get(ones_part[0], 0) if ones_part else 0
            return tens * 10 + ones
        total = 0
        for ch in text:
            if ch not in mapping:
                return None
            total = total * 10 + mapping[ch]
        return total
    
    # ========== ç¬¬ä¸‰å±¤ï¼šæœ€çµ‚é©—è­‰ ==========
    
    def final_validate(
        self,
        query: str,
        results: List[Dict],
        pre_analysis: PreAnalysisResult
    ) -> FinalValidationResult:
        """
        ç¬¬ä¸‰å±¤ï¼šæœ€çµ‚é©—è­‰
        
        ç”Ÿæˆç­”æ¡ˆå‰ï¼ŒLLM æœ€å¾Œç¢ºèªä¸€æ¬¡æª¢ç´¢çµæœæ˜¯å¦å®Œæ•´ã€‚
        
        Args:
            query: ç”¨æˆ¶æŸ¥è©¢
            results: æª¢ç´¢çµæœ
            pre_analysis: å‰ç½®åˆ†æçµæœ
            
        Returns:
            FinalValidationResult: é©—è­‰çµæœ
        """
        print(f"[Phase 2.5] ç¬¬ä¸‰å±¤ï¼šæœ€çµ‚é©—è­‰")
        
        citations_summary = self._format_citations_for_check(results)
        aspects_summary = "\n".join([
            f"- {a.type}ï¼š{a.description}" for a in pre_analysis.aspects
        ])
        
        # ğŸš€ å„ªåŒ–ï¼šç°¡åŒ– prompt
        prompt = f"""å°ç£å‹å‹•æ³•å°ˆå®¶ã€‚æœ€å¾Œç¢ºèªæ³•æ¢æ˜¯å¦å®Œæ•´ã€‚

å•é¡Œï¼š{query}
é¢å‘ï¼š{aspects_summary}
æ³•æ¢ï¼š{citations_summary}

èƒ½å®Œæ•´å›ç­”å—ï¼Ÿæœ‰éºæ¼å—ï¼Ÿ

JSONï¼š
{{
    "status": "PASS",
    "concerns": [],
    "missing_aspects": []
}}
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯æ³•å¾‹ç­”æ¡ˆå“è³ªæª¢æŸ¥å°ˆå®¶ã€‚å›ç­”å¿…é ˆæ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                response_format={"type": "json_object"}
            )
            
            result_json = json.loads(response.choices[0].message.content)
            result = FinalValidationResult(**result_json)
            
            print(f"[Phase 2.5] âœ“ æœ€çµ‚é©—è­‰: {result.status}")
            if result.concerns:
                print(f"[Phase 2.5]   âš ï¸ Concerns: {result.concerns}")
            
            return result
        
        except Exception as e:
            print(f"[Phase 2.5] âœ— é©—è­‰å¤±æ•—: {e}")
            # é™ç´šï¼šå‡è¨­é€šé
            return FinalValidationResult(
                status="WARNING",
                concerns=["æœ€çµ‚é©—è­‰å¤±æ•—ï¼Œè«‹è¬¹æ…åƒè€ƒç­”æ¡ˆ"],
                missing_aspects=[]
            )


# ============================================================
# Global Instance (Singleton)
# ============================================================

_INTELLIGENT_RETRIEVER_INSTANCE: Optional[IntelligentRetriever] = None


def get_intelligent_retriever(api_key: Optional[str] = None, model: str = "gpt-4o-mini") -> IntelligentRetriever:
    """
    ç²å–æ™ºèƒ½æª¢ç´¢å™¨å¯¦ä¾‹ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰
    
    Args:
        api_key: OpenAI API é‡‘é‘°
        model: LLM æ¨¡å‹åç¨±
        
    Returns:
        IntelligentRetriever å¯¦ä¾‹
    """
    global _INTELLIGENT_RETRIEVER_INSTANCE
    
    if _INTELLIGENT_RETRIEVER_INSTANCE is None:
        if not api_key:
            raise RuntimeError("API key required for first initialization")
        _INTELLIGENT_RETRIEVER_INSTANCE = IntelligentRetriever(api_key=api_key, model=model)
    
    return _INTELLIGENT_RETRIEVER_INSTANCE


def is_available() -> bool:
    """æª¢æŸ¥æ™ºèƒ½æª¢ç´¢å™¨æ˜¯å¦å¯ç”¨"""
    return OPENAI_AVAILABLE

