"""å¯©æ ¸å“¡ä»£ç†ï¼šè³ªé‡æ§åˆ¶èˆ‡é©—è­‰"""
from __future__ import annotations

from typing import Dict, List, Optional
import re
from pydantic import BaseModel

from .receptionist import AnalysisResult
from .lawyer import LawyerResponse
from ..citation_validator import CitationValidator
from ..law_guides import LawGuideEngine, TopicMatch


class ReviewResult(BaseModel):
    """å¯©æ ¸çµæœ"""
    decision: str  # PASS/REJECT/WARN
    citation_valid: Dict  # å¼•ç”¨é©—è­‰çµæœ
    quality_score: float  # 0-1
    feedback: str  # åé¥‹èªªæ˜
    errors: List[str] = []  # éŒ¯èª¤åˆ—è¡¨
    warnings: List[str] = []  # è­¦å‘Šåˆ—è¡¨


class SupervisorAgent:
    """
    å¯©æ ¸å“¡ä»£ç†ï¼šè² è²¬è³ªé‡æ§åˆ¶èˆ‡é©—è­‰
    
    è·è²¬ï¼š
    1. å¼•ç”¨é©—è­‰ï¼ˆæ•´åˆ Phase 0ï¼‰
    2. é‚è¼¯å®Œæ•´æ€§æª¢æŸ¥
    3. ç­”æ¡ˆè³ªé‡è©•ä¼°
    4. æ±ºç­–ï¼ˆé€šé/é€€å›/è­¦å‘Šï¼‰
    """
    
    def __init__(self):
        # æ•´åˆ Phase 0 çš„å¼•ç”¨é©—è­‰å™¨
        self.citation_validator = CitationValidator()
        try:
            self.law_guide_engine = LawGuideEngine()
        except Exception as exc:
            print(f"[Supervisor] Warning: failed to load law guides: {exc}")
            self.law_guide_engine = None
        
        # è³ªé‡é–¾å€¼
        self.quality_threshold = 0.7
        self.confidence_threshold = 0.6
    
    def review(
        self,
        lawyer_response: LawyerResponse,
        citations: List[Dict],
        analysis: AnalysisResult,
        query: str
    ) -> ReviewResult:
        """
        å¯©æ ¸å¾‹å¸«ç”Ÿæˆçš„ç­”æ¡ˆ
        
        Args:
            lawyer_response: å¾‹å¸«ä»£ç†çš„å›æ‡‰
            citations: åŸå§‹å¼•ç”¨
            analysis: æ¥å¾…å“¡åˆ†æçµæœ
            query: åŸå§‹æŸ¥è©¢
        """
        errors = []
        warnings = []
        
        # 1. å¼•ç”¨é©—è­‰ï¼ˆPhase 0ï¼‰
        citation_valid = self._validate_citations(
            lawyer_response,
            citations,
            analysis,
            query
        )
        
        # æ”¶é›†å¼•ç”¨é©—è­‰éŒ¯èª¤/è­¦å‘Š
        if not citation_valid.get("exists", True):
            errors.append("å¼•ç”¨çš„æ¢æ–‡ä¸å­˜åœ¨æ–¼è³‡æ–™åº«ä¸­")
        
        if citation_valid.get("conflicts", False):
            errors.append("å¼•ç”¨çš„æ¢æ–‡ä¹‹é–“å­˜åœ¨é‚è¼¯è¡çª")
        
        if not citation_valid.get("content_match", True):
            warnings.append("å¼•ç”¨å…§å®¹å¯èƒ½èˆ‡å®˜æ–¹ç‰ˆæœ¬æœ‰ç´°å¾®å·®ç•°")
        
        # ğŸ†• Phase 2.7: ä¸»é¡Œ-æ¢æ–‡ä¸€è‡´æ€§æª¢æŸ¥
        topic_citation_issues = self._check_topic_citation_consistency(
            query, citations
        )
        if topic_citation_issues.get("mismatch"):
            warnings.append(
                f"å¼•ç”¨æ¢æ–‡å¯èƒ½èˆ‡æŸ¥è©¢ä¸»é¡Œä¸ä¸€è‡´ï¼š{topic_citation_issues['mismatch']}"
            )
        if topic_citation_issues.get("missing_definition"):
            warnings.append(
                f"æŸ¥è©¢æ¶‰åŠå®šç¾©æ€§å•é¡Œï¼Œå»ºè­°è£œå……ï¼š{topic_citation_issues['missing_definition']}"
            )
        
        # 2. å¿…å‚™æ¢æ–‡æª¢æŸ¥
        missing_core = self._check_required_articles(analysis.topics, citations)
        if missing_core:
            errors.append(
                "ç¼ºå°‘é—œéµå¼•ç”¨ï¼š" + "ã€".join(missing_core)
            )
        
        # 3. é‚è¼¯å®Œæ•´æ€§æª¢æŸ¥
        logic_complete = self._check_logic_completeness(
            lawyer_response,
            analysis
        )
        
        if not logic_complete:
            warnings.append("ç­”æ¡ˆå¯èƒ½æœªå®Œæ•´è¦†è“‹æ‰€æœ‰å•é¡Œé¢å‘")
        
        # 4. ç­”æ¡ˆè³ªé‡è©•ä¼°
        quality_score = self._assess_quality(
            lawyer_response,
            citation_valid,
            logic_complete
        )
        
        # 5. æ±ºç­–
        decision, feedback = self._make_decision(
            citation_valid,
            quality_score,
            lawyer_response.confidence,
            errors,
            warnings
        )
        
        return ReviewResult(
            decision=decision,
            citation_valid=citation_valid,
            quality_score=quality_score,
            feedback=feedback,
            errors=errors,
            warnings=warnings
        )
    
    @staticmethod
    def _normalize_law_key(name: Optional[str]) -> str:
        if not name:
            return ""
        cleaned = re.sub(r"\s+", "", name)
        return cleaned.lower()

    def _check_topic_citation_consistency(
        self,
        query: str,
        citations: List[Dict]
    ) -> Dict:
        """
        ğŸ†• Phase 2.7: ä¸»é¡Œ-æ¢æ–‡ä¸€è‡´æ€§æª¢æŸ¥
        
        ä½¿ç”¨å¤šä¸»é¡ŒåŒ¹é…ä¾†ç¢ºä¿å¼•ç”¨çš„æ¢æ–‡èˆ‡æŸ¥è©¢ä¸»é¡Œä¸€è‡´ã€‚
        
        Returns:
            {
                "mismatch": str or None,  # ä¸ä¸€è‡´æè¿°
                "missing_definition": str or None  # ç¼ºå°‘çš„å®šç¾©æ€§æ¢æ–‡
            }
        """
        result = {"mismatch": None, "missing_definition": None}
        
        if not self.law_guide_engine:
            return result
        
        # ä½¿ç”¨å¤šä¸»é¡ŒåŒ¹é…
        matched_topics: List[TopicMatch] = self.law_guide_engine.match_topics(query, max_topics=3)
        
        if not matched_topics:
            return result
        
        # æ”¶é›†æ‰€æœ‰åŒ¹é…ä¸»é¡Œçš„æ ¸å¿ƒæ¢æ–‡
        expected_articles = set()
        definition_articles = []
        
        for match in matched_topics:
            for entry in match.guide.get("core_articles", []):
                law = entry.get("law", "")
                for art in entry.get("articles", []):
                    expected_articles.add((self._normalize_law_key(law), str(art).strip()))
                    # æ¨™è¨˜å®šç¾©æ€§æ¢æ–‡
                    if match.category == "definition":
                        definition_articles.append(f"{law}ç¬¬{art}æ¢")
        
        # æ”¶é›†å¯¦éš›å¼•ç”¨çš„æ¢æ–‡
        cited_articles = set()
        for c in citations:
            law = c.get("law_name") or c.get("law_id") or ""
            art = str(c.get("article_no", "")).strip()
            if law and art:
                cited_articles.add((self._normalize_law_key(law), art))
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ä¸»è¦ä¸»é¡Œçš„æ¢æ–‡å®Œå…¨ç¼ºå¤±
        best_topic = matched_topics[0]
        best_topic_articles = set()
        for entry in best_topic.guide.get("core_articles", []):
            law = entry.get("law", "")
            for art in entry.get("articles", []):
                best_topic_articles.add((self._normalize_law_key(law), str(art).strip()))
        
        # å¦‚æœæœ€ä½³åŒ¹é…ä¸»é¡Œçš„æ‰€æœ‰æ¢æ–‡éƒ½æ²’è¢«å¼•ç”¨ï¼Œå¯èƒ½æ˜¯ä¸»é¡Œä¸ä¸€è‡´
        if best_topic_articles and not (best_topic_articles & cited_articles):
            topic_name = best_topic.guide.get("name", best_topic.topic_id)
            result["mismatch"] = f"æŸ¥è©¢ä¸»é¡Œç‚ºã€Œ{topic_name}ã€ï¼Œä½†å¼•ç”¨æ¢æ–‡æœªåŒ…å«ç›¸é—œæ ¸å¿ƒæ¢æ–‡"
        
        # æª¢æŸ¥å®šç¾©æ€§æ¢æ–‡æ˜¯å¦ç¼ºå¤±ï¼ˆå°æ–¼ definition é¡å‹çš„ä¸»é¡Œï¼‰
        if definition_articles:
            definition_article_keys = set()
            for match in matched_topics:
                if match.category == "definition":
                    for entry in match.guide.get("core_articles", []):
                        law = entry.get("law", "")
                        for art in entry.get("articles", []):
                            definition_article_keys.add((self._normalize_law_key(law), str(art).strip()))
            
            missing_def = definition_article_keys - cited_articles
            if missing_def and best_topic.category == "definition":
                # Only warn if the primary topic is definition-type
                missing_list = [f"{law}ç¬¬{art}æ¢" for law, art in list(missing_def)[:2]]
                result["missing_definition"] = "ã€".join(missing_list)
        
        return result

    def _check_required_articles(
        self,
        topics: List[str],
        citations: List[Dict]
    ) -> List[str]:
        """
        æª¢æŸ¥æ¯å€‹ä¸»é¡Œçš„æ ¸å¿ƒæ¢æ–‡æ˜¯å¦å·²è¢«å¼•ç”¨ã€‚
        å¦‚æœç¼ºå°‘å‰‡è¿”å›ç¼ºæ¼åˆ—è¡¨ï¼ˆä¾›éŒ¯èª¤æç¤ºï¼‰ã€‚
        """
        if not topics or not self.law_guide_engine:
            return []
        
        seen = {
            (
                self._normalize_law_key(c.get("law_name") or c.get("law_id")),
                str(c.get("article_no", "")).strip()
            )
            for c in citations
        }
        missing: List[str] = []
        
        for topic in topics:
            guide = self.law_guide_engine.guides.get(topic) if self.law_guide_engine else None
            if not guide:
                continue
            topic_name = guide.get("name") or topic
            for entry in guide.get("core_articles", []):
                law_name = entry.get("law")
                articles = entry.get("articles") or []
                for art in articles:
                    art_no = str(art).strip()
                    key = (self._normalize_law_key(law_name), art_no)
                    if key in seen:
                        continue
                    label = f"{topic_name}ï¼š{law_name}ç¬¬{art_no}æ¢"
                    missing.append(label)
        return missing
    
    def _validate_citations(
        self,
        lawyer_response: LawyerResponse,
        citations: List[Dict],
        analysis: AnalysisResult,
        query: str
    ) -> Dict:
        """
        å¼•ç”¨é©—è­‰ï¼ˆæ•´åˆ Phase 0ï¼‰
        
        Returns:
            {
                "exists": bool,  # æ¢æ–‡å­˜åœ¨æ€§
                "content_match": bool,  # å…§å®¹ä¸€è‡´æ€§
                "conflicts": bool,  # é‚è¼¯è¡çª
                "whitelist_enforced": bool  # ç™½åå–®å¼·åˆ¶
            }
        """
        # ä½¿ç”¨ Phase 0 çš„é©—è­‰å™¨
        topic_name = analysis.topics[0] if analysis.topics else None
        
        # æº–å‚™å¼•ç”¨åˆ—è¡¨ï¼ˆæ ¼å¼è½‰æ›ï¼‰
        citation_list = []
        for c in citations:
            citation_list.append({
                "law_name": c.get("law_name") or c.get("law_id") or c.get("title"),
                "article_no": c.get("article_no", "").strip(),
                "heading": c.get("heading", ""),
                "text": c.get("text", "")
            })
        
        try:
            # èª¿ç”¨å®Œæ•´é©—è­‰
            validation_report = self.citation_validator.validate_all(
                query=query,
                citations=citation_list,
                topic=topic_name
            )
            
            # è½‰æ›ç‚ºç°¡åŒ–æ ¼å¼
            return {
                "exists": validation_report["overall_status"] != "FAIL",
                "content_match": len(validation_report["errors"]) == 0,
                "conflicts": any("è¡çª" in err for err in validation_report["errors"]),
                "whitelist_enforced": validation_report["action"] != "BLOCK"
            }
        
        except Exception as e:
            print(f"[Supervisor] Citation validation failed: {e}")
            # é™ç´šè™•ç†ï¼šåªæª¢æŸ¥åŸºæœ¬å­˜åœ¨æ€§
            return {
                "exists": len(citation_list) > 0,
                "content_match": True,  # ç„¡æ³•é©—è­‰ï¼Œé è¨­é€šé
                "conflicts": False,
                "whitelist_enforced": True
            }
    
    def _check_logic_completeness(
        self,
        lawyer_response: LawyerResponse,
        analysis: AnalysisResult
    ) -> bool:
        """
        æª¢æŸ¥é‚è¼¯å®Œæ•´æ€§
        
        ç°¡å–®ç­–ç•¥ï¼š
        - å¦‚æœæ˜¯ COMPLEX æŸ¥è©¢ï¼Œç­”æ¡ˆæ‡‰è©²è¶³å¤ é•·ä¸”åŒ…å«å¤šå€‹æ®µè½
        - å¦‚æœæœ‰å­å•é¡Œï¼Œç­”æ¡ˆæ‡‰è©²æ¶µè“‹æ‰€æœ‰å­å•é¡Œ
        """
        answer = lawyer_response.answer
        
        # å¦‚æœæ˜¯ COMPLEX æŸ¥è©¢
        if analysis.query_type == "COMPLEX":
            # æª¢æŸ¥ç­”æ¡ˆé•·åº¦ï¼ˆè‡³å°‘300å­—ï¼‰
            if len(answer) < 300:
                return False
            
            # æª¢æŸ¥æ˜¯å¦åŒ…å«å­å•é¡Œé—œéµè©
            if analysis.sub_questions:
                for sub_q in analysis.sub_questions:
                    # æå–é—œéµè©ï¼ˆç°¡åŒ–ç‰ˆï¼‰
                    keywords = [word for word in sub_q if len(word) > 1]
                    # è‡³å°‘50%çš„å­å•é¡Œé—œéµè©å‡ºç¾åœ¨ç­”æ¡ˆä¸­
                    if len(keywords) > 0:
                        matched = sum(1 for kw in keywords if kw in answer)
                        if matched / len(keywords) < 0.5:
                            return False
        
        return True
    
    def _assess_quality(
        self,
        lawyer_response: LawyerResponse,
        citation_valid: Dict,
        logic_complete: bool
    ) -> float:
        """
        è©•ä¼°ç­”æ¡ˆè³ªé‡ (0-1)
        
        è€ƒæ…®å› ç´ ï¼š
        1. å¾‹å¸«ä»£ç†çš„ä¿¡å¿ƒåº¦
        2. å¼•ç”¨é©—è­‰çµæœ
        3. ç­”æ¡ˆå®Œæ•´æ€§
        4. ä½¿ç”¨çš„å¼•ç”¨æ•¸é‡
        """
        score = 0.0
        
        # 1. åŸºç¤åˆ†æ•¸ï¼šå¾‹å¸«ä¿¡å¿ƒåº¦ (30%)
        score += lawyer_response.confidence * 0.3
        
        # 2. å¼•ç”¨é©—è­‰ (30%)
        citation_score = 0.0
        if citation_valid["exists"]:
            citation_score += 0.5
        if citation_valid["content_match"]:
            citation_score += 0.3
        if not citation_valid["conflicts"]:
            citation_score += 0.2
        score += citation_score * 0.3
        
        # 3. ç­”æ¡ˆå®Œæ•´æ€§ (25%) - æ–°å¢
        answer_length = len(lawyer_response.answer)
        if answer_length > 100:  # è‡³å°‘100å­—
            score += 0.15
        if "è³‡æ–™ä¸è¶³" not in lawyer_response.answer and "ç„¡æ³•åˆ¤å®š" not in lawyer_response.answer:
            score += 0.10  # âœ… çå‹µç©æ¥µå›ç­”
        
        # 4. é‚è¼¯å®Œæ•´æ€§ (15%)
        if logic_complete:
            score += 0.15
        
        return min(1.0, max(0.0, score))
    
    def _make_decision(
        self,
        citation_valid: Dict,
        quality_score: float,
        confidence: float,
        errors: List[str],
        warnings: List[str]
    ):
        """
        åšå‡ºæ±ºç­–
        
        Returns:
            (decision, feedback)
            decision: PASS/REJECT/WARN
        """
        # REJECT æ¢ä»¶
        if errors:
            feedback = "ç­”æ¡ˆå­˜åœ¨åš´é‡éŒ¯èª¤ï¼Œç„¡æ³•é€šéå¯©æ ¸ï¼š\n" + "\n".join(f"- {err}" for err in errors)
            return "REJECT", feedback
        
        if not citation_valid["exists"]:
            feedback = "å¼•ç”¨çš„æ³•å¾‹æ¢æ–‡ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆ"
            return "REJECT", feedback
        
        if citation_valid["conflicts"]:
            feedback = "å¼•ç”¨çš„æ¢æ–‡ä¹‹é–“å­˜åœ¨é‚è¼¯è¡çªï¼Œéœ€è¦é‡æ–°æª¢æŸ¥"
            return "REJECT", feedback
        
        # WARN æ¢ä»¶
        if quality_score < self.quality_threshold:
            feedback = f"ç­”æ¡ˆè³ªé‡è©•åˆ† {quality_score:.2f} ä½æ–¼é–¾å€¼ {self.quality_threshold}ï¼Œå»ºè­°è¬¹æ…ä½¿ç”¨"
            return "WARN", feedback
        
        if confidence < self.confidence_threshold:
            feedback = f"ç³»çµ±ä¿¡å¿ƒåº¦ {confidence:.2f} è¼ƒä½ï¼Œå»ºè­°è«®è©¢å°ˆæ¥­å¾‹å¸«ç¢ºèª"
            return "WARN", feedback
        
        if warnings:
            feedback = "ç­”æ¡ˆå¯ç”¨ï¼Œä½†æœ‰ä»¥ä¸‹æé†’ï¼š\n" + "\n".join(f"- {warn}" for warn in warnings)
            return "WARN", feedback
        
        # PASS
        feedback = f"ç­”æ¡ˆé€šéå¯©æ ¸ï¼ˆè³ªé‡è©•åˆ†ï¼š{quality_score:.2f}ï¼Œä¿¡å¿ƒåº¦ï¼š{confidence:.2f}ï¼‰"
        return "PASS", feedback

